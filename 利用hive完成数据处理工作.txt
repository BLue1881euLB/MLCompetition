利用hive完成阿里天池大数据音乐预测比赛数据处理工作
hive shell 
创建内部表
CREATE TABLE songs (sid string,aid string,ptime string, sinit int,language int,gender int) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ; 
导入HDFS文件(原文件消失)
LOAD DATA INPATH '/bs/music/input/mars_tianchi_songs.csv' OVERWRITE INTO TABLE songs;
#查看表结构
desc songs; 


创建外表，指定目录
CREATE EXTERNAL TABLE IF NOT EXISTS songs2 (
sid string,
aid string,
ptime string,
sinit int,
language int,
gender int) 
COMMENT 'This is the staging page view table'   
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION  '/bs/music/songs/'; 
导入HDFS文件(原文件消失)
LOAD DATA INPATH '/bs/music/input/mars_tianchi_songs.csv' OVERWRITE INTO TABLE songs2;
查看前10条数据
select * from songs2 limit 10;
创建外表，指定目录
CREATE EXTERNAL TABLE IF NOT EXISTS useraction (
uid string,
sid string,
btime string,
atype int,
ds string) 
COMMENT 'This is the staging page view table'   
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION  '/bs/music/useraction/'; 
导入HDFS文件(原文件消失)
LOAD DATA INPATH '/bs/music/input/mars_tianchi_user_actions.csv' OVERWRITE INTO TABLE useraction;
select * from useraction limit 10;
表连接 小表在前
SELECT t1.*,t2.* FROM songs2 t1 JOIN useraction t2 on t1.sid=t2.sid;
Map join连接
SELECT /*+mapjoin(songs2)*/ t1.*,t2.* FROM songs2 t1 JOIN useraction t2 on t1.sid=t2.sid;
导出查询数据到hdfs 
INSERT OVERWRITE DIRECTORY '/bs/music/data' 
SELECT /*+mapjoin(songs2)*/ t1.*,t2.* FROM songs2 t1 JOIN useraction t2 on t1.sid=t2.sid;
查询结果保存到表
CREATE EXTERNAL TABLE IF NOT EXISTS usersongs (
sid string,      歌曲唯一标识
aid string,      歌曲所属的艺人
ptime string,    歌曲发行时间，精确到天
sinit int,       歌曲的初始播放数，表明该歌曲的初始热度
language int,    语种
gender int,      性别  
uid string,      用户唯一标识
sid2 string,     歌曲唯一标识
btime string,    用户播放时间
atype int,       为类型：1，播放；2，下载，3，收藏
ds string)       记录收集日（分区）
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION  '/bs/music/data/'; 
INSERT OVERWRITE TABLE usersongs 
SELECT /*+mapjoin(songs2)*/ t1.*,t2.* FROM songs2 t1 JOIN useraction t2 on t1.sid=t2.sid;
查询结果保存到本地 bin目录下hive命令
hive -e "select * from usersongs limit 10" >> /opt/tools/test.csv
查看HDFS上文件的前5行
hadoop fs -text  /bs/music/data/000000_0 |head -n 5
去重分组查询 同一aid的uid去重总量，sid的去重总量  播放行为的每个艺人的用户总量 歌曲总量
select count(distinct uid),count(distinct sid),aid from usersongs  where atype=1 group by aid;
desc usersongs; 
select * from usersongs  where sid='effb071415be51f11e845884e67c0f8c' limit 10;
每首歌每天的播放量
select sid,ds,count(atype) from usersongs  where atype=1  group by sid,ds order by sid,ds;
hive -e "select sid,ds,count(atype) from usersongs  where atype=1  group by sid,ds order by sid,ds" >> /opt/tools/s_count1.csv
每首歌每天的下载量
select sid,ds,count(atype) from usersongs  where atype=2  group by sid,ds order by sid,ds;
hive -e "select sid,ds,count(atype) from usersongs  where atype=2 group by sid,ds order by sid,ds" >> /opt/tools/s_count2.csv
每首歌每天的收藏量
select sid,ds,count(atype) from usersongs  where atype=3  group by sid,ds order by sid,ds;
hive -e "select sid,ds,count(atype) from usersongs  where atype=3  group by sid,ds order by sid,ds" >> /opt/tools/s_count3.csv
每个用户的每首歌每天的播放量
select uid,sid,ds,count(atype) from usersongs  where atype=1  group by uid,sid,ds order by uid,sid,ds;
hive -e "select uid,sid,ds,count(atype) from usersongs  where atype=1  group by uid,sid,ds order by uid,sid,ds" >> /opt/tools/u_s_count1.csv
每个用户的每首歌每天的下载量
hive -e "select uid,sid,ds,count(atype) from usersongs  where atype=2  group by uid,sid,ds order by uid,sid,ds" >> /opt/tools/u_s_count2.csv
每个用户的每首歌每天的收藏量
hive -e "select uid,sid,ds,count(atype) from usersongs  where atype=3  group by uid,sid,ds order by uid,sid,ds" >> /opt/tools/u_s_count3.csv


